```markdown
## Chosen Approach
Unit tests for service worker handlers using Chrome API mocks and spying on real internal collaborators.

## Rationale
- **Simplicity:** This approach is the most direct way to test the handlers as they are, without requiring significant refactoring upfront, while still adhering to the mocking policy.
- **Modularity + Strict Separation:** By mocking only external Chrome APIs and using the real internal modules (`cache.ts`, `api.ts`), we respect the boundary between the service worker's core logic (which interacts with `cache` and `api`) and the external environment (`chrome`). We verify the interaction *between* internal modules via the handler's behavior, which is a form of integration testing at the handler level, compliant with the "Integration / Workflow Tests (High Priority)" guideline using real internal collaborators.
- **Testability (minimal mocking):** Mocking is strictly limited to the external Chrome APIs, adhering to the "Mock ONLY True External System Boundaries" rule. Internal collaborators are used directly, and their interactions are verified via spying, not mocking their implementation. This forces tests to interact with the actual code, providing higher confidence.
- **Coding Standards:** Leverages standard testing patterns (mocking external dependencies, spying on function calls) within a TypeScript environment.
- **Documentation Approach:** Tests serve as executable documentation for handler behavior.

## Build Steps
1.  **Set up Testing Framework:** Ensure a suitable testing framework (e.g., Jest, Vitest) is configured for the project, capable of running in a Node.js environment or similar that can simulate browser/service worker contexts.
2.  **Create Mock Chrome APIs:** Create mock implementations for `chrome.runtime` and `chrome.alarms`. These mocks should simulate the relevant parts of the Chrome API used by `service-worker/index.ts`, specifically:
    *   `chrome.runtime.onMessage`: Provide an `addListener` function that stores the provided listener callback. The test will then call this stored callback directly to simulate receiving a message. Add a mock `sendResponse` function to the message event arguments if used by handlers, allowing tests to verify if it's called.
    *   `chrome.alarms.onAlarm`: Provide an `addListener` function that stores the provided listener callback. The test will call this stored callback to simulate an alarm firing.
    *   Mock any other `chrome.*` methods *called by* the handlers (e.g., `chrome.runtime.sendMessage`, `chrome.alarms.create`) to verify they are invoked correctly.
3.  **Import Real Internal Modules:** In the test files, import the actual `cache.ts` and `api.ts` modules.
4.  **Spy on Internal Functions:** For each test or test suite, use the testing framework's spying capabilities (e.g., `jest.spyOn`, `vi.spyOn`) to spy on the specific functions within `cache.ts` and `api.ts` that the handlers are expected to interact with (e.g., `cache.get`, `cache.set`, `api.fetchData`). Ensure spies are restored after each test to prevent leakage.
5.  **Write Test Cases per Handler:**
    *   **Message Handler:**
        *   Write tests to simulate receiving messages with different `message.type` values or commands.
        *   Verify that the correct internal functions (`cache.*`, `api.*`) are called based on the message type, with the expected arguments.
        *   Test scenarios where the internal function calls succeed and return data.
        *   Test scenarios where the internal function calls fail (e.g., throw an error), verifying how the handler responds (e.g., logging, sending an error response).
        *   If `sendResponse` is used, verify it is called with the correct data or error.
    *   **Alarm Handler:**
        *   Write tests to simulate alarms firing with different `alarm.name` values.
        *   Verify that the correct internal functions (`cache.*`, `api.*`) are called based on the alarm name, with the expected arguments.
        *   Test success and failure scenarios for internal function calls.
    *   **Other Handlers (install, activate, fetch):** If `service-worker/index.ts` contains logic within listeners for `install`, `activate`, or `fetch` events, write tests to simulate these events and verify the corresponding logic interacts correctly with internal modules or Chrome APIs.
6.  **Ensure Coverage:** Review test coverage reports (generated by the test runner) to identify uncovered lines or branches within the handler functions. Add specific test cases to cover these areas (e.g., missing `if/else` branches, error paths). Aim for >80% coverage as required.
7.  **Refactor if Necessary:** If, during testing, a handler function is found to be overly complex, mixing multiple distinct operations or interacting with many dependencies, consider refactoring. Extract core logic interacting with `cache` and `api` into separate functions that can be tested more easily by passing dependencies as arguments, leaving the original handler as a thin layer that receives the Chrome event and calls the extracted logic. Test the extracted functions and the simplified handler.
8.  **Automate Test Execution:** Integrate test execution and coverage checks into the CI pipeline. Ensure the build fails if tests do not pass or coverage thresholds are not met.
```